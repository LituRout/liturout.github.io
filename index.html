<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Litu Rout</title>

  <meta name="author" content="Litu Rout">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/jpg" href="images/UT_profile.png">
  <style>
  div {
    opacity: 0.5;
  }
  </style>
  <style>
  #more {display: none;}
  </style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Litu Rout</name>
              </p>
              <p> I am a first year PhD student at <a href="https://www.utexas.edu/">The University of Texas Austin</a>, advised by <a href="https://caramanis.github.io/"> Prof. Constantine Caramanis </a> and <a href="https://sites.google.com/view/sanjay-shakkottai/home"> Prof. Sanjay Shakkottai</a>. I am interested in the theoretical foundations of machine learning, generative modeling, stochastic optimization, and optimal transport.
              </p>
              
              <p>Prior to UT Austin, I worked as a Scientist/Engineer-SD at the<!--  Space Applications Centre <a href="https://www.sac.gov.in/Vyom/index.jsp">(SAC)</a>, --> <a href="https://www.isro.gov.in/"> Indian Space Research Organisation</a>, where I developed operational deep learning algorithms and analyzed their convergence properties. 
              </p>
              <p>
              I received my BTech from the Indian Institute of Space Science and Technology <a href="https://www.iist.ac.in/">(IIST)</a>. I was fortunate to be advised by <a href="https://sites.google.com/site/gorthisaisubrahmanyam/"> Prof. Rama Krishna Gorthi</a> and <a href="https://www.iist.ac.in/avionics/deepak.mishra">Prof. Deepak Mishra</a> during my undergraduate research.<!--  My bachelor's <a href="data/BTech_Thesis.pdf"> thesis</a> received the <a href="https://www.inae.in/recipients-of-innovative-student-projects-award/">Innovative Student Project Award</a> offered by the Indian National Academy of Engineering <a href="https://www.inae.in/">(INAE)</a>-->
              </p>
              <p style="text-align:center">
                <a href="mailto:litu.rout@utexas.edu">Contact</a> &nbsp/&nbsp
                <!-- <a href="data/litu_rout.pdf">CV</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.co.in/citations?user=GYy7fWwAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://www.researchgate.net/profile/Litu_Rout">ResearchGate</a> &nbsp/&nbsp -->
                <!-- <a href="https://orcid.org/0000-0002-5054-5899">ORCID</a> &nbsp/&nbsp -->
                <a href="https://dblp.org/pid/206/6445.html">DBLP</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/litu-rout/">LinkedIn</a> &nbsp/&nbsp           
                <a href="https://github.com/LituRout">GitHub</a> <!-- &nbsp/&nbsp  -->                    
                <!-- <a href="https://www.semanticscholar.org/author/Litu-Rout/26427844">Semantic Scholar</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/litu_rout_web.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/litu_rout_web.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

<!-- Updates========================================================================================== -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Updates</heading>
              </td>
              </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <!--========================================================================================== -->
          <td>
            <ul>
	      <li><b>Jul 2023: </b> New preprint: <a href="https://arxiv.org/pdf/2307.00619.pdf">Solving Linear Inverse Problems Provably via Posterior Sampling with Latent Diffusion Models</a>!</li>
              <p></p>
	      <li><b>May 2023: </b> Excited to start summer internship in <a href="https://www.qualcomm.com/research/artificial-intelligence/ai-research">Qualcomm AI Research</a>, San Diego, CA!</li>
              <p></p>
              <li><b>Feb 2023: </b> One paper <a href="https://arxiv.org/pdf/2302.06570.pdf">Beyond Uniform Smoothness: A Stopped Analysis of Adaptive SGD</a> accepted at COLT 2023.</li>
              <p></p>
              <li><b>Feb 2023: </b> New preprint: <a href="https://arxiv.org/pdf/2302.01217.pdf">A Theoretical Justification for Image Inpainting using Diffusion Models</a>.</li>
              <p></p>              
              <li><b>Jan 2023: </b> One paper <a href="https://openreview.net/forum?id=CUOaVn6mYEj">Hierarchical Sliced Wasserstein Distance</a> accepted at ICLR 2023.</li>
              <p></p>
	      <span id="dots"></span><span id="more">                            		    
              <li><b>Sep 2022: </b> Received Cockrell School of Engineering Fellowship from UT Austin.</li>
              <p></p>
              <li> <b>Apr 2022:</b> Presented <a href="https://openreview.net/forum?id=5JdLZg346Lw">Generative Modeling with Optimal Transport Maps</a> at ICLR 2022.</li>
              <p></p>
              <li> <b>Apr 2021:</b> Published a paper on <a href="https://www.sciencedirect.com/science/article/abs/pii/S0032063321000544"> Phobos image enhancement </a> at <a href = "https://www.sciencedirect.com/journal/planetary-and-space-science"> Planetary and Space Science Journal</a>.</li>
              <p></p>
              <li> <b>Feb 2021:</b> Presented a paper on <a href="https://arxiv.org/abs/2010.00521"> Turing Instability in Adversarial Learning </a> at <a href = "https://aaai.org/Conferences/AAAI-21/"> AAAI 2021 </a>.</li>
              <p></p> 
              <li> <b>Dec 2020:</b> Presented the <a href=""> Pseudo-Reaction-Diffusion paper </a> at the <a href = "https://neurips.cc/"> NeurIPS </a> workshop on <a href="https://ml4physicalsciences.github.io/2020/" >ML4PS</a>.</li>
              <p></p> 
              <li> <b>Sep 2020:</b> <b>Patent</b> granted: <a href="data/patent_certificate.pdf">A Method for Sequential Information Condensation using Fourier Basis</a>.</li>
              <p></p>
              <li> <b>Jun 2020:</b> Presented <b>two papers</b> at the <a href="http://cvpr2020.thecvf.com/">CVPR</a> workshop on <a href="https://www.grss-ieee.org/earthvision2020/">Large Scale Computer Vision for Remote Sensing Imagery</a>.</li>
              <!-- <li> <b>April 2020:</b> <b>Two papers</b> got accepted at <a href="http://cvpr2020.thecvf.com/">CVPR</a> Workshop on <a href="https://www.grss-ieee.org/earthvision2020/">Large Scale Computer Vision for Remote Sensing Imagery</a>!</li> -->
              <p></p>
              <li> <b>Jan 2020:</b> Published <a href="https://ieeexplore.ieee.org/document/8961195">ALERT</a> in the <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36">IEEE Transactions on Geoscience and Remote Sensing</a>, <b>impact factor: 5.85</b>.</li>
              <p></p>
              <li> <b>Dec 2018:</b> Received the <a href="https://www.inae.in/innovative-student-projects-award/">Innovative Student Project Award</a> for excellence in engineering and technology.
              </span>
            </ul>
            <button onclick="myFunction()" id="myBtn">More</button>
            <p></p>
          </td>
        </tbody>
      </table>

        <script>
        function myFunction() {
          var dots = document.getElementById("dots");
          var moreText = document.getElementById("more");
          var btnText = document.getElementById("myBtn");

          if (dots.style.display === "none") {
            dots.style.display = "inline";
            btnText.innerHTML = "More"; 
            moreText.style.display = "none";
          } else {
            dots.style.display = "none";
            btnText.innerHTML = "Less"; 
            moreText.style.display = "inline";
          }
        }
        </script>



<!-- Research========================================================================================== -->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                 I study <b>AI</b> at the intersection of <b> Optimization, Interactive Machine Learning, and Optimal Transport </b> including the <b>mathematical foundations of Deep Learning</b>. I primarily focus my research on <b>building</b> artificially intelligent <b>machines</b> that <b>perceive</b> the <b>world</b> from sensory data the way <b>humans</b> do. Following is a selected list of my publications. For a complete list, please see my <a href="https://scholar.google.co.in/citations?user=GYy7fWwAAAAJ&hl=en">Google Scholar</a> profile. 
             </p>
            </td>
          </tr>
        </tbody></table>
 -->
 <!-- Service========================================================================================== -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Reviewer</heading>
              <p>
                 Neurips (2022, 2023), ICML (2022, 2023), ICLR (2022, 2023), AISTATS (2023), Pattern Recognition (2022), NeurIPS ML4PS (2021).
              </p>
            </td>
          </tr>
        </tbody></table>

      
        <!-- Publications==========================================================================================-->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>

        <!-- 2023==========================================================================================-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Diffusion Probabilistic Models</heading>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src='images/psld.png'>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <mark style="color:red"><b>NEW</b></mark> &nbsp <a href="https://arxiv.org/abs/2307.00619"><papertitle>Solving Linear Inverse Problems Provably via Posterior Sampling with Latent Diffusion Models
            </papertitle></a>
            <br>
            <strong>Litu Rout</strong>, Negin Raoof, Giannis Daras, Constantine Caramanis, Alex Dimakis, and Sanjay Shakkottai
            <br>
            <em>Preprint</em>, 2023
            <br><!-- 
            <a href="">OpenReview</a> &nbsp <a href="">PDF</a> &nbsp -->
            <a href="https://arxiv.org/pdf/2307.00619.pdf">ArXiv</a> &nbsp <a href="https://github.com/LituRout/PSLD">Code</a> &nbsp <a href="https://huggingface.co/spaces/PSLD/PSLD">Demo</a>
            <p></p>
            <p> Solving inverse problems (e.g. inpainting/deblurring) for general domain images is hard. Magic Eraser and other commercial tools use separately trained models for each task. We introduce PSLD, a method that uses Stable Diffusion to solve all linear problems without any extra training.</p>
          </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/repaintplus.png'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <mark style="color:red"><b>NEW</b></mark> &nbsp <a href="https://arxiv.org/abs/2302.01217"><papertitle>A Theoretical Justification for Image Inpainting using Denoising Diffusion Probabilistic Models</papertitle></a>
              <br>
              <strong>Litu Rout</strong>, Advait Parulekar, Constantine Caramanis, and Sanjay Shakkottai
              <br>
              <em>Preprint</em>, 2023
              <br><!-- 
              <a href="">OpenReview</a> &nbsp <a href="">PDF</a> &nbsp -->
              <a href="https://arxiv.org/pdf/2302.01217.pdf">ArXiv</a> <!-- &nbsp <a href="">Code</a> -->
              <p></p>
              <p>We provide a theoretical justification for sample recovery using diffusion based image inpainting in a linear model setting. Unlike most inpainting algorithms, we prove that diffusion based inpainting generalizes well to unseen masks without retraining. Motivated by our analysis, we propose a modified RePaint algorithm we call RePaint+ that provably recovers the underlying true sample and enjoys a linear rate of convergence. </p>
            </td>
         </tr>
        </tbody></table>


        <!-- 2022==========================================================================================-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Stochastic Optimization</heading>
          </td>
        </tr>
      </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src='images/Stop_sign.png'>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <mark style="color:red"><b>NEW</b></mark> &nbsp <a href="https://arxiv.org/abs/2302.06570"><papertitle>Beyond Uniform Smoothness: A Stopped Analysis of Adaptive SGD</papertitle></a>
            <br>
            Matthew Faw*, <strong>Litu Rout*</strong>, Constantine Caramanis, and Sanjay Shakkottai
            <br>
            <em>COLT</em>, 2023 &nbsp (* Equal contribution)
            <br><!-- 
            <a href="">OpenReview</a> &nbsp <a href="">PDF</a> &nbsp -->
            <a href="https://arxiv.org/pdf/2302.06570.pdf">ArXiv</a> <!-- &nbsp <a href="">Code</a> -->
            <p></p>
            <p> We develop a technique that allows us to prove convergence rates for (L<sub>0</sub>, L<sub>1</sub>)-smooth functions without assuming uniform bounds on the noise support. The key innovation behind our results is a carefully constructed stopping time. This is simultaneously large on average and allows us to decorrelate the adaptive stepsizes from the gradients, which is a major challenge in many analyses.</p>
          </td>
       </tr>
      </tbody></table>


        <!-- 2022==========================================================================================-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Optimal Transport</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!--==========================================================================================-->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/otm.png'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=5JdLZg346Lw"><papertitle>Generative Modeling with Optimal Transport Maps</papertitle></a>
              <br>
              <strong>Litu Rout</strong>, Alexander Korotin, and Evgeny Burnaev
              <br>
              <em>ICLR</em>, 2022
              <br>
              <a href="https://openreview.net/forum?id=5JdLZg346Lw">OpenReview</a> &nbsp <a href="https://openreview.net/pdf?id=5JdLZg346Lw">PDF</a> &nbsp <a href="https://arxiv.org/pdf/2110.02999.pdf">ArXiv</a> &nbsp <a href="data/OTM_presentation_ICLR2022.pdf"> Slides </a> &nbsp <a href="data/OTM_poster_ICLR2022.pdf">Poster</a> &nbsp <a href="https://github.com/LituRout/OptimalTransportModeling">Code</a>
              <p></p>
              <p>While Optimal Transport (OT) cost serves as the loss for popular generative models, we demonstrate that the OT map can be used as the generative model itself. Previous analogous approaches consider OT maps as generative models only in the latent spaces due to their poor performance in the original high-dimensional ambient space. In contrast, we fit OT maps directly in the ambient space, e.g., a space of high-dimensional images. </p>
            </td>
         </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/hsw.png'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=CUOaVn6mYEj"><papertitle>Hierarchical Sliced Wasserstein Distance</papertitle></a>
              <br>
              Khai Nguyen, Tongzheng Ren, Huy Nguyen, <strong>Litu Rout</strong>, Tan Nguyen, and Nhat Ho
              <br>
              <em>ICLR</em>, 2023
              <br>
              <a href="https://openreview.net/forum?id=CUOaVn6mYEj">OpenReview</a> &nbsp <a href="https://openreview.net/pdf?id=CUOaVn6mYEj">PDF</a> &nbsp <a href="https://arxiv.org/pdf/2209.13570.pdf">ArXiv</a> <!-- &nbsp <a href="">Code</a> -->
              <p></p>
              <p>A major concern of Sliced Wasserstein (SW) distance is that it requires a large number of projections in high-dimensional settings. To address this concern, we derive projections from a small number of bottleneck projections. We introduce Hierachical Radon Transform (HRT) that recursively applies Radon Transform (RT). We design Hierarchical Sliced Wasserstein (HSW) distance to estimate the discrepancy between measures in high dimensions. </p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/ots.png'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2202.01116.pdf"><papertitle>Unpaired Image Super-Resolution with Optimal Transport Maps</papertitle></a>
              <br>
              Milena Gazdieva, <strong>Litu Rout</strong>, Alexander Korotin, Alexander Filippov, and Evgeny Burnaev
              <br>
              <em>Preprint</em>, 2022
              <br>
              <!-- <a href="https://openreview.net/forum?id=5JdLZg346Lw">OpenReview</a> &nbsp <a href="data/preprint1_2021.pdf">PDF</a> &nbsp --> <a href="https://arxiv.org/pdf/2202.01116.pdf">ArXiv</a> <!-- &nbsp <a href="">Code</a> -->
              <p></p>
              <p>First, we prove that GANs with content or identity losses learn optimal transport (OT) maps between source and target measures in super-resolution tasks. Second, we empirically demonstrate that these learned OT maps are biased and provide an OT solver to recover an unbiased OT map. It provides nearly state-of-the-art performance on the unpaired AIM19 benchmark without having to use content or identity losses.</p>
            </td>
         </tr>
        </tbody></table>
         <!--==========================================================================================-->

         <!-- 2021==========================================================================================-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Neural Network Learning Theory &amp Representation Learning</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src='images/gray_scott.png'>
          </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <!-- <mark style="color:red"><b>NEW</b></mark> &nbsp --> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17137"><papertitle>Why Adversarial Interaction Creates Non-Homogeneous Patterns: A Pseudo-Reaction-Diffusion Model for Turing Instability</papertitle></a>
                    <br>
                    <strong>Litu Rout</strong>
                    <br>
                    <em> AAAI </em> (<b>acceptance rate: 21%</b>), 2021 (Extended Version) 
                    <br>
                    <a href="data/aaai21_preprint.pdf">PDF</a> &nbsp <a href="https://arxiv.org/abs/2010.00521">ArXiv</a> &nbsp <a href="data/aaai21_slides.pdf">Slides</a> &nbsp <a href="data/aaai21_poster.pdf">Poster</a> &nbsp <a href="data/aaai21_teaser.mp4"> Teaser </a> &nbsp <a href="https://slideslive.com/38947721/why-adversarial-interaction-creates-nonhomogeneous-patterns-a-pseudoreactiondiffusion-model-for-turing-instability">Presentation</a>
                    <p></p>
                    <p>In this paper, we intend to demystify an interesting phenomenon: <em>adversarial interaction in GANs creates non-homogeneous equilibrium by inducing Turing instability in a Pseudo-Reaction-Diffusion (PRD) model</em>. This is in contrast to supervised learning where the identical model achieves homogeneous equilibrium.</p>
                </td>
        </tr>
      <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/fmnist_ker.png'>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ml4physicalsciences.github.io/2020/"><papertitle>Towards A Pseudo-Reaction-Diffusion Model for Turing Instability in Adversarial Learning</papertitle></a>
        <br>
        <strong>Litu Rout</strong>
        <br>
        <em> NeurIPS ML4PS Workshop</em>, 2020 (Short Version)
        <br>
        <a href="https://ml4physicalsciences.github.io/2020/files/NeurIPS_ML4PS_2020_1.pdf">PDF</a> &nbsp <a href="https://ml4physicalsciences.github.io/2020/files/NeurIPS_ML4PS_2020_1_poster.pdf">Poster</a> &nbsp <a href="https://arxiv.org/abs/2010.00521">ArXiv</a>
        <p></p>
        <p>In this study, we observe that a system in which a generator and a discriminator adversarially interact with each other exhibits Turing-like patterns in the hidden layer and top layer of the generator.
        </p>
      </td>
      </tr>
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='images/mnist_nta.png'>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://aisecure-workshop.github.io/amlcvpr2021/"><papertitle>Understanding the Role of Adversarial Regularization in Supervised Learning</papertitle></a>
          <br>
          <strong>Litu Rout</strong>
          <br>
          <em>CVPR Adversarial ML Workshop</em>, 2021
          <br>
          <a href="data/cvpr2021_aml_cv.pdf">PDF</a>
          <p></p>
          <p>Despite numerous attempts sought to provide empirical evidence of adversarial regularization outperforming sole supervision, the theoretical understanding of such phenomena remains elusive. In this study, we aim to resolve whether adversarial regularization indeed performs better than sole supervision at a fundamental level.</p>
        </td>
        </tr>
    </tbody></table>
    

           
         <!-- 2021==========================================================================================-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Generative Adversarial Networks &amp Satellite Image Processing</heading>
            </td>
          </tr>
        </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!--==========================================================================================-->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/alert.png'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/8961195">
                <papertitle>ALERT: Adversarial Learning with Expert Regularization using Tikhonov Operator for Missing Band Reconstruction</papertitle>
              </a>
              <br>
              <strong>Litu Rout</strong>
              <br>
              <em>TGRS</em> (<b>impact factor: 5.85</b>), 2020
              <br>
              <a href="https://ieeexplore.ieee.org/document/8961195">PDF</a> &nbsp <a href="data/alert.pdf">Preprint</a>
              <p></p>
              <p>In this article, we devise a method, which we call ALERT, to tackle missing band reconstruction. The proposed method reconstructs missing band with the sole supervision of spectral and spatial priors.</p>
            </td>
          </tr>
         <!--==========================================================================================-->
	     		  
	    <!-- </tbody></table> -->

		<!-- 2020==========================================================================================-->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>2020</heading>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->
		<!--==========================================================================================-->
		
        
        <!--==========================================================================================-->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/s2a.png'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://openaccess.thecvf.com/content_CVPRW_2020/html/w11/Rout_S2A_Wasserstein_GAN_With_Spatio-Spectral_Laplacian_Attention_for_Multi-Spectral_Band_CVPRW_2020_paper.html">
                <papertitle>S2A: Wasserstein GAN with Spatio-Spectral Laplacian Attention for Multi-Spectral Band Synthesis</papertitle>
              </a>
              <br>
              <strong>Litu Rout</strong>, Indranil Misra, S Manthira Moorthi, and Debajyoti Dhar
              <br>
              <em>CVPR Earth Vision Workshop, Oral Talk</em> (<b>acceptance rate: 26%</b>), 2020
              <br>
              <a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w11/Rout_S2A_Wasserstein_GAN_With_Spatio-Spectral_Laplacian_Attention_for_Multi-Spectral_Band_CVPRW_2020_paper.pdf">PDF</a> &nbsp <a href="https://arxiv.org/abs/2004.03867">ArXiv</a> &nbsp <a href="data/309-talk.pdf">Slides</a>&nbsp <a href="https://www.grss-ieee.org/earthvision2020/july_stuff/webpage/talks/309.html">Presentation</a> <!-- &nbsp <a href=""> Code </a> -->
              <p></p>
              <p>This paper seeks to address synthesis of high resolution multi-spectral satellite imagery using adversarial learning. Guided by the discovery of attention mechanism, we regulate the process of band synthesis through spatio-spectral Laplacian attention.</p>
            </td>
          </tr>

        <!--==========================================================================================-->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/spoa.png'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://openaccess.thecvf.com/content_CVPRW_2020/html/w11/Rout_Monte-Carlo_Siamese_Policy_on_Actor_for_Satellite_Image_Super_Resolution_CVPRW_2020_paper.html">
                <papertitle>Monte-Carlo Siamese Policy on Actor for Satellite Image Super Resolution</papertitle>
              </a>
              <br>
              <strong>Litu Rout</strong>, Saumyaa Shah, S Manthira Moorthi, and Debajyoti Dhar
              <br>
              <em>CVPR Earth Vision Workshop, Oral Talk</em> (<b>acceptance rate: 26%</b>), 2020
              <br>
              <a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w11/Rout_Monte-Carlo_Siamese_Policy_on_Actor_for_Satellite_Image_Super_Resolution_CVPRW_2020_paper.pdf">PDF</a> &nbsp <a href="https://arxiv.org/abs/2004.03879">ArXiv</a> <!-- &nbsp <a href="https://github.com/LituRout/MC-SPOA">Code</a> --> &nbsp <a href="data/324-talk.pdf">Slides</a> &nbsp <a href="https://www.grss-ieee.org/earthvision2020/july_stuff/webpage/talks/324.html">Presentation</a>
              <p></p>
              <p>In this study, we propose to parameterize action variables by matrices, and train our policy network using Monte-Carlo sampling. We study the implications of parametric action space in a model-free environment from theoretical and empirical perspective.</p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/phobos.png'>
            </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <!-- <mark style="color:red"><b>NEW</b></mark> &nbsp --> <a href="https://www.sciencedirect.com/journal/planetary-and-space-science"><papertitle>Phobos Image Enhancement using Unpaired Multi-Frame Acquisitions from Indian Mars Color Camera </papertitle></a>
                    <br>
                    Indranil Misra, <strong>Litu Rout</strong>, Sunita Arya, Yatharath Bhateja, S Manthira Moorthi, and Debajyoti Dhar
                    <br>
                    <!-- <em> Planetary and Space Science </em> (<b>impact factor: 1.782</b>), 2021   -->
                    <em> Planetary and Space Science </em>, 2021  
                    <br>
                    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0032063321000544">PDF</a> &nbsp <a href="data/planet.pdf">Preprint</a>
                    <p></p>
                    <p>This paper describes the techniques developed to enhance the Phobos image from MCC multi-frame acquisitions using image rectification and topographic data. After incorporating these techniques, the final Phobos image appears more representative, spatially enhanced, and has normalized radiometry to study its surface features.</p>
                </td>
             </tr>
          <!--==========================================================================================-->
    

          <!--==========================================================================================-->
            
            </tbody></table>


        <!-- 2019==========================================================================================-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Visual Object Tracking</heading>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		<!--==========================================================================================-->

	       <tr>
	         <td style="padding:20px;width:25%;vertical-align:middle">
	           <img src='images/iccv.png'>
	         </td>
	         <td style="padding:20px;width:75%;vertical-align:middle">
	           <a href="http://openaccess.thecvf.com/content_ICCVW_2019/html/VOT/Kristan_The_Seventh_Visual_Object_Tracking_VOT2019_Challenge_Results_ICCVW_2019_paper.html">
	             <papertitle>The seventh visual object tracking vot2018 challenge results</papertitle>
	           </a>
	           <br>
	           Matej Kristan, Ales Leonardis, Jiri Matas, Michael Felsberg, Roman, Pflugfelder, <strong>Litu Rout</strong> and others
	           <br>
	           <em>ICCV VOT Workshop</em>, 2019
	           <br>
	           <a href="http://openaccess.thecvf.com/content_ICCVW_2019/html/VOT/Kristan_The_Seventh_Visual_Object_Tracking_VOT2019_Challenge_Results_ICCVW_2019_paper.html">PDF</a>
	           <p></p>
	           <p>Results of 81 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years.</p>
	         </td>
	       </tr>
          <!--==========================================================================================-->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/mog.png'>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://link.springer.com/article/10.1007/s12046-019-1100-6">
                  <papertitle>Application of image enhancement and mixture of Gaussian approach in combustion research</papertitle>
                </a>
                <br>
                <strong>Litu Rout</strong>, Rajesh Sadanandan and Deepak Mishra
                <br>
                <em>Sadhana, Indian Academy of Sciences</em>, 2019
                <br>
                <a href="https://link.springer.com/article/10.1007/s12046-019-1100-6">PDF</a> &nbsp <a href="https://www.ias.ac.in/describe/article/sadh/044/05/0114">IAS</a>
                <p></p>
                <p>The developed algorithm has been implemented to yield the physically significant chemiluminescence emission from hydroxyl radicals in flames from line-of-sight integrated images. The effectiveness of this algorithm is highlighted using exemplary OH chemiluminescence images captured from a standard swirl stabilized research burner.</p>
              </td>
            </tr>
            <!-- </tbody></table> -->


        <!-- 2018==========================================================================================-->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>2018</heading>
            </td>
          </tr>
        </tbody></table> -->
        
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->
		<!--==========================================================================================-->

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <video width=100% height=100% muted autoplay loop>
                <source src="images/matrix_crop.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-20890-5_41">
                <papertitle>Learning Rotation Adaptive Correlation Filters in Robust Visual Object Tracking</papertitle>
              </a>
              <br>
              <strong>Litu Rout</strong>, Priya Mariam Raju, Deepak Mishra, and Rama Krishna Gorthi
              <br>
              <em>ACCV</em>, 2018
              <br>
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-20890-5_41">PDF</a> &nbsp <a href="https://arxiv.org/abs/1906.01551">ArXiv</a> &nbsp <a href="data/ACCV_conference_presentation_.pdf">Slides</a>
              <p></p>
              <p>Here, we propose a robust framework that offers the provision to incorporate illumination and rotation invariance in the standard Discriminative Correlation Filter (DCF) formulation. We also supervise the detection stage of DCF trackers by eliminating false positives in the convolution response map.</p>
            </td>
          </tr>

          <!--==========================================================================================-->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <video width=100% height=100% muted autoplay loop>
                <source src="images/waef_crop.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://openaccess.thecvf.com/content_eccv_2018_workshops/w1/html/Rout_WAEF_Weighted_Aggregation_with_Enhancement_Filter_for_Visual_Object_Tracking_ECCVW_2018_paper.html">
                <papertitle>WAEF: Weighted Aggregation with Enhancement Filter for Visual Object Tracking</papertitle>
              </a>
              <br>
              <strong>Litu Rout</strong>, Deepak Mishra and Rama Krishna Gorthi
              <br>
              <em>ECCV VOT Workshop</em>, 2018
              <br>
              <a href="http://openaccess.thecvf.com/content_eccv_2018_workshops/w1/html/Rout_WAEF_Weighted_Aggregation_with_Enhancement_Filter_for_Visual_Object_Tracking_ECCVW_2018_paper.html">PDF</a>
              <p></p>
              <p>This paper discusses a novel approach to regress in temporal domain, based on weighted aggregation of distinctive visual features and feature prioritization with entropy estimation in a recursive fashion.</p>
            </td>
          </tr>
         <!--==========================================================================================-->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/eccv.png'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://openaccess.thecvf.com/content_eccv_2018_workshops/w1/html/Kristan_The_sixth_Visual_Object_Tracking_VOT2018_challenge_results_ECCVW_2018_paper.html">
                <papertitle>The sixth visual object tracking vot2018 challenge results</papertitle>
              </a>
              <br>
              Matej Kristan, Ales Leonardis, Jiri Matas, Michael Felsberg, Roman, Pflugfelder, <strong>Litu Rout</strong> and others
              <br>
              <em>ECCV VOT Workshop</em>, 2018
              <br>
              <a href="http://openaccess.thecvf.com/content_eccv_2018_workshops/w1/html/Kristan_The_sixth_Visual_Object_Tracking_VOT2018_challenge_results_ECCVW_2018_paper.html">PDF</a>
              <p></p>
              <p>Results of over eighty trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years.</p>
            </td>
          </tr>
          <!--==========================================================================================-->

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <video width=100% height=100% muted autoplay loop>
                <source src="images/wacv_crop.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/8354224">
                <papertitle>Rotation Adaptive Visual Object Tracking with Motion Consistency</papertitle>
              </a>
              <br>
              <strong>Litu Rout</strong>, Sidhartha, Deepak Mishra, and Rama Krishna Gorthi
              <br>
              <em>WACV</em>, 2018
              <br>
              <a href="https://ieeexplore.ieee.org/document/8354224">PDF</a> &nbsp <a href="https://arxiv.org/abs/1709.06057">ArXiv</a> &nbsp <a href="https://github.com/LituRout/SiameseFC-DSR">Code</a> &nbsp <a href='data/wacv_50.pdf'>Slides</a> &nbsp <a href="data/WACV18-poster-paper-50.pdf">Poster</a> &nbsp<a href="https://www.youtube.com/watch?v=UvnBla8fTJo">Presentation</a>
              <p></p>
              <p>In this paper, we study the necessity to capture various physical constraints through motion consistency which has been demonstrated to improve accuracy, robustness and more importantly rotation adaptiveness.</p>
            </td>
          </tr>
        </tbody></table>

 <!-- Patents==========================================================================================-->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Patent</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/patent.png'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/patent_certificate.pdf"><papertitle>A Method for Sequential Information Condensation using Fourier Basis</papertitle></a>
              <br>
              <a href="https://en.wikipedia.org/wiki/Tapan_Misra">Tapan Misra</a>, <strong>Litu Rout</strong>
              <br>
              <em>SAC, ISRO</em>, 2020
              <br>
              Patent No. 346206,  Application No. 202041004166
              <br>
              <p></p>
              <p>The present embodiment proposes an efficient Fast Fourier Transform (FFT) based hyper-spectral image compression technique to store multiple acquisitions over same region of interest and thereby, improve Signal to Noise Ratio (SNR) of hyper-spectral images which usually have coarse spatial resolution.</p>
            </td>
          </tr>
        </tbody></table>

<!-- Chapters==========================================================================================-->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Chapters</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/accv_book.png'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.springer.com/gp/book/9783030208899">
                <papertitle>Learning Rotation Adaptive Correlation Filters in Robust Visual Object Tracking</papertitle>
              </a>
              <br>
              <strong>Litu Rout</strong>, Priya Mariam Raju, Deepak Mishra, and Rama Krishna Gorthi
              <br>
              <em>Computer Vision – ACCV</em>, 2018
              <br>
              <p></p>
              <p>In this chapter, we propose a robust framework that offers the provision to incorporate illumination and rotation invariance in the standard Discriminative Correlation Filter (DCF) formulation. We also supervise the detection stage of DCF trackers by eliminating false positives in the convolution response map.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/eccv_vot_book.png'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.springer.com/gp/book/9783030110086">
                <papertitle>WAEF: Weighted Aggregation with Enhancement Filter for Visual Object Tracking</papertitle>
              </a>
              <br>
              <strong>Litu Rout</strong>, Deepak Mishra and Rama Krishna Gorthi
              <br>
              <em>Computer Vision – ECCV Workshops</em>, 2018
              <br>
              <p></p>
              <p> This chapter discusses a novel approach to regress in the temporal domain, based on weighted aggregation of distinctive visual features and feature prioritization with entropy estimation in a recursive fashion.</p>
            </td>
          </tr>

        </tbody></table>

<!-- Preprints==========================================================================================-->

       <!--  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Preprints</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


        
         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/otm.png'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href=""><papertitle>Generative Modeling with Optimal Transport Maps</papertitle></a>
              <br>
              <strong>Litu Rout</strong>, Alexander Korotin, and Evgeny Burnaev
              <br>
              <a href="data/preprint1_2021.pdf">PDF</a> &nbsp <a href="https://arxiv.org/abs/2010.00522">ArXiv</a>
              <p></p>
              <p>While Optimal Transport (OT) cost serves as the loss for popular generative models, we demonstrate that the OT map can be used as the generative model itself. Previous analogous approaches consider OT maps as generative models only in the latent spaces due to their poor performance in the original high-dimensional ambient space. In contrast, we apply OT maps directly in the ambient space, e.g., a space of high-dimensional images. </p>
            </td>
         </tr>
        </tbody></table> -->



<!-- Invited Talk========================================================================================== -->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Tutorials</heading>
              </td>
              </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->
      <!--========================================================================================== -->
       <!--    <td>
            <ul>
              <li> <b>June 2021:</b> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17137">Why Adversarial Interaction Creates Non-Homogeneous Patterns: A Pseudo-Reaction-Diffusion Model for Turing Instability</a>, Knowledge Sharing Series on Artificial Intelligence: Theory and Practice, SAC, ISRO, India.
                <br>
                  <a href="data/KSS_Lecture1_02062021.pdf">[Lecture 1]</a> &nbsp <a href="data/KSS_Lecture2_09062021.pdf">[Lecture 2]</a> &nbsp <a href="data/KSS_Lecture3_16062021.pdf">[Lecture 3]</a> &nbsp <a href="data/Learning_a_Linear_Function_Approximator.html">[Demo Code 1]</a> &nbsp <a href="data/Learning_One_Layer_Neural_Network_Function_Approximator.html">[Demo Code 2]</a> &nbsp <a href="data/Learning_Two_Layer_Neural_Network_Function_Approximator.html">[Demo Code 3]</a> &nbsp <a href="data/Learning_Three_Layer_Convolutional_Neural_Network_Function_Approximator.html">[Demo Code 4]</a></li>
              <p></p>
              <li> <b>August 2020:</b> <b>Deep Learning: Real World Applications and Implementation Details</b>, Human Resource Development Division (HRDD), VSSC, ISRO, India.
                <br>
                  <a href="data/vssc_talk_aug_2020_lr.pdf">[Slides]</a> &nbsp <a href="data/Learning_a_Linear_Function_Approximator.html">[Demo Code 1]</a> &nbsp <a href="data/Learning_One_Layer_Neural_Network_Function_Approximator.html">[Demo Code 2]</a> &nbsp <a href="data/Learning_Two_Layer_Neural_Network_Function_Approximator.html">[Demo Code 3]</a> &nbsp <a href="data/Learning_Three_Layer_Convolutional_Neural_Network_Function_Approximator.html">[Demo Code 4]</a></li>
              <p></p>
              <li> <b>April 2020:</b> <a href="http://openaccess.thecvf.com/content_CVPRW_2020/html/w11/Rout_S2A_Wasserstein_GAN_With_Spatio-Spectral_Laplacian_Attention_for_Multi-Spectral_Band_CVPRW_2020_paper.html">S2A: Wasserstein GAN with Spatio-Spectral Laplacian Attention for Multi-Spectral Band Synthesis</a>, Earth, Ocean, Atmosphere, Planetary Sciences and Applications Area (EPSA), SAC, ISRO, India.
                <br>
                 <a href="data/309-talk.pdf">[Slides]</a></li>
              <p></p>
              <li> <b>April 2020:</b> <a href="http://openaccess.thecvf.com/content_CVPRW_2020/html/w11/Rout_Monte-Carlo_Siamese_Policy_on_Actor_for_Satellite_Image_Super_Resolution_CVPRW_2020_paper.html"> Monte-Carlo Siamese Policy on Actor for Satellite Image Super Resolution</a>, Earth, Ocean, Atmosphere, Planetary Sciences and Applications Area (EPSA), SAC, ISRO, India.
                <br>
                 <a href="data/324-talk.pdf">[Slides]</a></li>
              <p></p>
              <li> <b>March 2020:</b> <b>Global and Local Residual Learning for Spatio-Spectral Synthesis of SWIR Band using Multi-Sensor Concurrent Datasets</b>, National Remote Sensing Agencies, SAC, ISRO, India. </li>
              <p></p>
              <li> <b>July 2018:</b> <b>Understanding Artificial Neural Networks to Deep Learning</b>, Mohandas College of Engineering and Technology <a href="https://mcetonline.com/">(MCET)</a>, Thiruvananthapuram, Kerala, India.</li>
            </ul>
            <p></p> -->
            <!--==========================================================================================-->
			<!-- Page visitors -->
			<!--==========================================================================================-->
			<!-- map widget -->
			       <!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=12kD2ArDBbodu3fRjVPsyL6j_66fWZ0yr4SIFZMXDgA'></script> -->
			<!-- flag widget -->
				<!-- <a href="https://info.flagcounter.com/Kaa5"><img src="https://s04.flagcounter.com/count2/Kaa5/bg_FFFFFF/txt_000000/border_CCCCCC/columns_4/maxflags_20/viewers_3/labels_1/pageviews_1/flags_0/percent_0/" alt="Flag Counter" border="0"></a> -->
			        
        <!--   </td>
        </tbody></table> -->

        
    	
<!--==========================================================================================-->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:45%;vertical-align:middle">
            </td>
            <td style="padding:20px;width:55%;vertical-align:middle">
              <!-- <div> Thanks to <a href="https://jonbarron.info/">Jon Barron</a> for the template.</div> -->
              <a href="https://jonbarron.info/">Website Template</a>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
